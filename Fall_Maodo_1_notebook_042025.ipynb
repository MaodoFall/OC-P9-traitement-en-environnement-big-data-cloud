{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441159cc",
   "metadata": {},
   "source": [
    "# Déploiment de la solution dans le cloud\n",
    "\n",
    "Maintenant que nous avons vérifié que notre solution fonctionne, <br />\n",
    "il est temps de la <u>déployer à plus grande échelle sur un vrai cluster de machines</u>.\n",
    "\n",
    "**Attention**, *je travaille sous Linux avec une version Ubuntu, <br />\n",
    "les commandes décrites ci-dessous sont donc réalisées <br />\n",
    "exclusivement dans cet environnement.*\n",
    "\n",
    "<u>Plusieurs contraintes se posent</u> :\n",
    " 1. Quel prestataire de Cloud choisir ?\n",
    " 2. Quelles solutions de ce prestataire adopter ?\n",
    " 3. Où stocker nos données ?\n",
    " 4. Comment configurer nos outils dans ce nouvel environnement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0f7c1",
   "metadata": {},
   "source": [
    "\n",
    " # 1 Choix du prestataire cloud : AWS\n",
    "\n",
    "Le prestataire le plus connu et qui offre à ce jour l'offre <br />\n",
    "la plus large dans le cloud computing est **Amazon Web Services** (AWS).<br />\n",
    "Certaines de leurs offres sont parfaitement adaptées à notre problématique <br />\n",
    "et c'est la raison pour laquelle j'utiliserai leurs services.\n",
    "\n",
    "L'objectif premier est de pouvoir, grâce à AWS, <u>louer de la puissance de calcul à la demande</u>. <br />\n",
    "L'idée étant de pouvoir, quel que soit la charge de travail, <br />\n",
    "obtenir suffisamment de puissance de calcul pour pouvoir traiter nos images, <br />\n",
    "même si le volume de données venait à fortement augmenter.\n",
    "\n",
    "De plus, la capacité d'utiliser cette puissance de calcul à la demande <br />\n",
    "permet de diminuer drastiquement les coûts si l'on compare les coûts d'une location <br />\n",
    "de serveur complet sur une durée fixe (1 mois, 1 année par exemple).\n",
    "\n",
    "# 2 Choix de la solution technique : EMR\n",
    "\n",
    "<u>Plusieurs solutions s'offre à nous</u> :\n",
    "1. Solution **IAAS** (Infrastructure AS A Service)\n",
    " - Dans cette configuration **AWS** met à notre disposition des serveurs vierges <br />\n",
    "   sur lequel nous avons un accès en administrateur, ils sont nommés **instance EC2**.<br />\n",
    "   Pour faire simple, nous pouvons avec cette solution reproduire pratiquement <br />\n",
    "   à l'identique la solution mis en œuvre en local sur notre machine.<br />\n",
    "   <u>On installe nous-même l'intégralité des outils puis on exécute notre script</u> :\n",
    "  - Installation de **Spark**, **Java** etc.\n",
    "  - Installation de **Python** (via Anaconda par exemple)\n",
    "  - Installation de **Jupyter Notebook**\n",
    "  - Installation des **librairies complémentaires**\n",
    "  - Il faudra bien évidement veiller à **implémenter les librairies \n",
    "    nécessaires à toutes les machines (workers) du cluster**\n",
    "  - <u>Avantages</u> :\n",
    "      - Liberté totale de mise en œuvre de la solution\n",
    "      - Facilité de mise en œuvre à partir d'un modèle qui s'exécute en local sur une machine Linux\n",
    "  - <u>Inconvénients</u> :\n",
    "      - Cronophage\n",
    "          - Nécessité d'installer et de configurer toute la solution\n",
    "      - Possible problèmes techniques à l'installation des outils (des problématiques qui <br />\n",
    "        n'existaient pas en local sur notre machine peuvent apparaitre sur le serveur EC2)\n",
    "      - Solution non pérenne dans le temps, il faudra veiller à la mise à jour des outils <br />\n",
    "        et éventuellement devoir réinstaller Spark, Java etc. \n",
    "2. Solution **PAAS** (Plateforme As A Service)\n",
    " - **AWS** fournit énormément de services différents, dans l'un de ceux-là <br />\n",
    "   il existe une offre qui permet de louer des **instances EC2** <br />\n",
    "   avec des applications préinstallées et configurées : il s'agit du **service EMR**.\n",
    " - **Spark** y sera déjà installé\n",
    " - Possibilité de demander l'installation de **Tensorflow** ainsi que **JupyterHub**\n",
    " - Possibilité d'indiquer des **packages complémentaires** à installer <br />\n",
    "   à l'initialisation du serveur **sur l'ensemble des machines du cluster**.\n",
    " - <u>Avantages</u> :\n",
    "     - Facilité de mise en œuvre\n",
    "         - Il suffit de très peu de configuration pour obtenir <br />\n",
    "           un environnement parfaitement fonctionnel\n",
    "     - Rapidité de mise en œuvre\n",
    "         - Une fois la première configuration réalisée, il est très facile <br />\n",
    "           et très rapide de recréer des clusters à l'identique qui seront <br />\n",
    "           disponibles presque instantanément (le temps d'instancier les <br />\n",
    "           serveurs soit environ 15/20 minutes)\n",
    "     - Solutions matérielless et logicielles optimisées par les ingénieurs d'AWS\n",
    "         - On sait que les versions installées vont fonctionner <br />\n",
    "           et que l'architecture proposée est optimisée\n",
    "     - Stabilité de la solution\n",
    "    - Solution évolutive\n",
    "        Il est facile d’obtenir à chaque nouvelle instanciation une version à jour <br />\n",
    "        de chaque package, en étant garanti de leur compatibilité avec le reste de l’environnement.\n",
    "  - Plus sécurisé\n",
    "\t- Les éventuels patchs de sécurité seront automatiquement mis à jour <br />\n",
    "      à chaque nouvelle instanciation du cluster EMR.\n",
    " - <u>Inconvénients</u> :\n",
    "     - Peut-être un certain manque de liberté sur la version des packages disponibles ? <br />\n",
    "       Même si je n'ai pas constaté ce problème.\n",
    "   \n",
    "\n",
    "Je retiens la solution **PAAS** en choisissant d'utiliser <br />\n",
    "le service **EMR** d'Amazon Web Services.<br />\n",
    "Je la trouve plus adaptée à notre problématique et permet <br />\n",
    "une mise en œuvre qui soit à la fois plus rapide et <br />\n",
    "plus efficace que la solution IAAS.\n",
    "\n",
    "# 3 Choix de la solution de stockage des données : Amazon S3\n",
    "\n",
    "<u>Amazon propose une solution très efficace pour la gestion du stockage des données</u> : **Amazon S3**. <br />\n",
    "S3 pour Amazon Simple Storage Service.\n",
    "\n",
    "Il pourrait être tentant de stocker nos données sur l'espace alloué par le serveur **EC2**, <br />\n",
    "mais si nous ne prenons aucune mesure pour les sauvegarder ensuite sur un autre support, <br />\n",
    "<u>les données seront perdues</u> lorsque le serveur sera résilié (on résilie le serveur lorsqu'on <br />\n",
    "ne s'en sert pas pour des raisons de coût).<br />\n",
    "De fait, si l'on décide d'utiliser l'espace disque du serveur EC2 il faudra imaginer <br />\n",
    "une solution pour sauvegarder les données avant la résiliation du serveur.\n",
    "De plus, nous serions exposés à certaines problématiques si nos données venaient à <br />\n",
    "**saturer** l'espace disponible de nos serveurs (ralentissements, disfonctionnements).\n",
    "\n",
    "<u>Utiliser **Amazon S3** permet de s'affranchir de toutes ces problématiques</u>. <br />\n",
    "L'espace disque disponible est **illimité**, et il est **indépendant de nos serveurs EC2**. <br />\n",
    "L'accès aux données est **très rapide** car nous restons dans l'environnement d'AWS <br />\n",
    "et nous prenons soin de <u>choisir la même région pour nos serveurs **EC2** et **S3**</u>.\n",
    "\n",
    "De plus, comme nous le verrons <u>il est possible d'accéder aux données sur **S3** <br />\n",
    "    de la même manière que l'on **accède aux données sur un disque local**</u>.<br />\n",
    "Nous utiliserons simplement un **PATH au format s3://...** .\n",
    "\n",
    "# 4 Configuration de l'environnement de travail\n",
    "\n",
    "La première étape est d'installer et de configurer [**AWS Cli**](https://aws.amazon.com/fr/cli/),<br />\n",
    "il s'agit de l'**interface en ligne de commande d'AWS**.<br />\n",
    "Elle nous permet d'**interagir avec les différents services d'AWS**, comme **S3** par exemple.\n",
    "\n",
    "Pour pouvoir utiliser **AWS Cli**, il faut le configurer en créant préalablement <br />\n",
    "un utilisateur à qui on donnera les autorisations dont nous aurons besoin.<br />\n",
    "Dans ce projet il faut que l'utilisateur ait à minima un contrôle total sur le service S3.\n",
    "\n",
    "<u>La gestion des utilisateurs et de leurs droits s'effectue via le service **AMI**</u> d'AWS.\n",
    "\n",
    "Une fois l'utilisateur créé et ses autorisations configurées nous créons une **paire de clés** <br />\n",
    "qui nous permettra de nous **connecter sans à avoir à devoir saisir systématiquement notre login/mot de passe**.<br />\n",
    "\n",
    "Il faut également configurer l'**accès SSH** à nos futurs serveurs EC2. <br />\n",
    "Ici aussi, via un système de clés qui nous dispense de devoir nous authentifier \"à la main\" à chaque connexion.\n",
    "\n",
    "Toutes ses étapes de configuration sont parfaitement décrites <br />\n",
    "dans le cours du projet: [Découvrez le cloud avec Amazon Web Services / Faites vos premiers pas sur AWS](https://openclassrooms.com/fr/courses/4810836-decouvrez-le-cloud-avec-amazon-web-services/7821712-faites-vos-premiers-pas-sur-aws)\n",
    "\n",
    "#  5 Upload de nos données sur S3\n",
    "\n",
    "Nos outils sont configurés. <br />\n",
    "Il faut maintenant uploader nos données de travail sur Amazon S3.\n",
    "\n",
    "Ici aussi les étapes sont décrites avec précision <br />\n",
    "dans le cours [Découvrez le cloud avec Amazon Web Services / Stockez et accédez à des fichiers sur Amazon S3](https://openclassrooms.com/fr/courses/4810836-decouvrez-le-cloud-avec-amazon-web-services/7822690-stockez-et-accedez-a-des-fichiers-sur-amazon-s3)\n",
    "\n",
    "Je décide de n'uploader que les données contenues dans le dossier **Test** du [jeu de données du projet](https://www.kaggle.com/moltean/fruits/download)\n",
    "\n",
    "\n",
    "La première étape consiste à **créer un bucket sur S3** <br />\n",
    "dans lequel nous uploaderons les données du projet:\n",
    "- **aws s3 mb s3://p8-data**\n",
    "\n",
    "On vérifie que le bucket à bien été créé\n",
    "- **aws s3 ls**\n",
    " - Si le nom du bucket s'affiche alors c'est qu'il a été correctement créé.\n",
    "\n",
    "On copie ensuite le contenu du dossier \"**Test**\" <br />\n",
    "dans un répertoire \"**Test**\" sur notre bucket \"**p8-data**\":\n",
    "1. On se place à l'intérieur du répertoire **Test**\n",
    "2. **aws sync . s3://p8-data/Test**\n",
    "\n",
    "La commande **sync** est utile pour synchroniser deux répertoires.\n",
    "\n",
    "<u>Nos données du projet sont maintenant disponibles sur Amazon S3</u>.\n",
    "\n",
    "# 6 Configuration du serveur EMR\n",
    "\n",
    "Une fois encore, le cours [Découvrez le cloud avec Amazon Web Services / Découvrez les services d'Amazon EC2](https://openclassrooms.com/fr/courses/4810836-decouvrez-le-cloud-avec-amazon-web-services/7822091-demarrez-votre-premiere-instance-ec2) <br /> détaille l'essentiel des étapes pour lancer un cluster avec **EMR**.\n",
    "\n",
    "<u>Je détaillerai ici les étapes particulières qui nous permettent <br />\n",
    "de configurer le serveur selon nos besoins</u> :\n",
    "\n",
    "1. Cliquez sur Créer un cluster\n",
    "![Créer un cluster](img/EMR_creer.png)\n",
    "2. Cliquez sur Accéder aux options avancées\n",
    "![Créer un cluster](img/EMR_options_avancees.png)\n",
    "\n",
    "## 6.1 Étape 1 : Logiciels et étapes\n",
    "\n",
    "###  6.1.1 Configuration des logiciels\n",
    "\n",
    "<u>Sélectionnez les packages dont nous aurons besoin comme dans la capture d'écran</u> :\n",
    "1. Nous sélectionnons la dernière version d'**EMR**, soit la version **6.3.0** au moment où je rédige ce document\n",
    "2. Nous cochons bien évidement **Hadoop** et **Spark** qui seront préinstallés dans leur version la plus récente\n",
    "3. Nous aurons également besoin de **TensorFlow** pour importer notre modèle et réaliser le **transfert learning**\n",
    "4. Nous travaillerons enfin avec un **notebook Jupyter** via l'application **JupyterHub**<br />\n",
    " - Comme nous le verrons dans un instant nous allons <u>paramétrer l'application afin que les notebooks</u>, <br />\n",
    "   comme le reste de nos données de travail, <u>soient enregistrés directement sur S3</u>.\n",
    "![Créer un cluster](img/EMR_configuration_logiciels.png)\n",
    "\n",
    "### 6.1.2 Modifier les paramètres du logiciel\n",
    "\n",
    "<u>Paramétrez la persistance des notebooks créés et ouvert via JupyterHub</u> :\n",
    "- On peut à cette étape effectuer des demandes de paramétrage particulières sur nos applications. <br />\n",
    "  L'objectif est, comme pour le reste de nos données de travail, <br />\n",
    "  d'éviter toutes les problématiques évoquées précédemment. <br />\n",
    "  C'est l'objectif à cette étape, <u>nous allons enregistrer <br />\n",
    "  et ouvrir les notebooks</u> non pas sur l'espace disque de  l'instance EC2 (comme <br />\n",
    "  ce serait le cas dans la configuration par défaut de JupyterHub) mais <br />\n",
    "  <u>directement sur **Amazon S3**</u>.\n",
    "- <u>deux solutions sont possibles pour réaliser cela</u> :\n",
    " 1. Créer un **fichier de configuration JSON** que l'on **upload sur S3** et on indique ensuite le chemin d’accès au fichier JSON\n",
    " 2. Rentrez directement la configuration au format JSON\n",
    " \n",
    "J'ai personnellement créé un fichier JSON lors de la création de ma première instance EMR, <br />\n",
    "puis lorsqu'on décide de cloner notre serveur pour en recréer un facilement à l'identique, <br />\n",
    "la configuration du fichier JSON se retrouve directement copié comme dans la capture ci-dessous.\n",
    "\n",
    "<u>Voici le contenu de mon fichier JSON</u> :  [{\"classification\":\"jupyter-s3-conf\",\"properties\":{\"s3.persistence.bucket\":\"p8-data\",\"s3.persistence.enabled\":\"true\"}}]\n",
    " Appuyez ensuite sur \"**Suivant**\"\n",
    "![Modifier les paramètres du logiciel](img/EMR_parametres_logiciel.png)\n",
    "\n",
    "## 6.2 Étape 2 : Matériel\n",
    "\n",
    "A cette étape, laissez les choix par défaut. <br />\n",
    "<u>L'important ici est la sélection de nos instances</u> :\n",
    "\n",
    "1. je choisi les instances de type **M5** qui sont des **instances de type équilibrés**\n",
    "2. je choisi le type **xlarge** qui est l'instance la **moins onéreuse disponible**\n",
    " [Plus d'informations sur les instances M5 Amazon EC2](https://aws.amazon.com/fr/ec2/instance-types/m5/)\n",
    "3. Je sélectionne **1 instance Maître** (le driver) et **2 instances Principales** (les workeurs) <br />\n",
    "   soit **un total de 3 instance EC2**.\n",
    "![Choix du materiel](img/EMR_materiel.png)\n",
    "\n",
    "## 6.3 Étape 3 : Paramètres de cluster généraux\n",
    "\n",
    "### 6.3.1 Options générales\n",
    "<u>La première chose à faire est de donner un nom au cluster</u> :<br />\n",
    "*J'ai également décoché \"Protection de la résiliation\" pour des raisons pratiques.*\n",
    "    \n",
    "![Nom du Cluster](img/EMR_nom_cluster.png)\n",
    "\n",
    "### 6.3.2 Actions d'amorçage\n",
    "\n",
    "Nous allons à cette étape **choisir les packages manquants à installer** et qui <br />\n",
    "nous serons utiles dans l'exécution de notre notebook.<br />\n",
    "<u>L'avantage de réaliser cette étape maintenant est que les packages <br />\n",
    "installés le seront sur l'ensemble des machines du cluster</u>.\n",
    "\n",
    "Nous créons un fichier nommé \"**bootstrap-emr.sh**\" que nous <u>uploadons <br />\n",
    "sur S3</u>(je l’installe à la racine de mon **bucket \"p8-data\"**) et nous l'ajoutons <br />\n",
    "comme indiqué dans la capture d'écran ci-dessous:\n",
    "![Actions d'amorcage](img/EMR_amorcage.png)\n",
    "\n",
    "Voici le contenu du fichier **bootstrap-emr.sh**<br />\n",
    "Comme on peut le constater il s'agit simplement de commande \"**pip install**\" <br />\n",
    "pour **installer les bibliothèques manquantes** comme réalisé en local.<br />\n",
    "Une fois encore, <u>il est nécessaire de réaliser ces actions à cette étape</u> <br />\n",
    "pour que <u>les packages soient installés sur l'ensemble des machines du cluster</u> <br />\n",
    "et non pas uniquement sur le driver, comme cela serait le cas si nous exécutions <br />\n",
    "ces commandes directement dans le notebook JupyterHub ou dans la console EMR (connecté au driver).\n",
    "![Contenu du fichier bootstrap](img/EMR_bootstrap.png)\n",
    "\n",
    "**setuptools** et **pip** sont mis à jour pour éviter une problématique <br />\n",
    "avec l'installation du package **pyarrow**.<br />\n",
    "**Pandas** a eu droit à une mise à jour majeur (1.3.0) il y a moins d'une semaine <br />\n",
    "au moment de la rédaction de ce notebook, et la nouvelle version de **Pandas** <br />\n",
    "nécessite une version plus récente de **Numpy** que la version installée par <br />\n",
    "défaut (1.16.5) à l'initialisation des instances **EC2**. <u>Il ne semble pas <br />\n",
    "possible d'imposer une autre version de Numpy que celle installé par <br />\n",
    "défaut</u> même si on force l'installation d'une version récente de **Numpy** <br />\n",
    "(en tout cas, ni simplement ni intuitivement).<br />\n",
    "La mise à jour étant très récente <u>la version de **Numpy** n'est pas encore <br />\n",
    "mise à jour sur **EC2**</u> mais on peut imaginer que ce sera le cas très rapidement <br />\n",
    "et il ne sera plus nécessaire d'imposer une version spécifique de **Pandas**.<br />\n",
    "En attendant, je demande <u>l'installation de l'avant dernière version de **Pandas (1.2.5)**</u>\n",
    "\n",
    "On clique ensuite sur ***Suivant***\n",
    "\n",
    "## 6.4 Étape 4 : Sécurité\n",
    "\n",
    "### 6.4.1 Options de sécurité\n",
    "\n",
    "A cette étape nous sélectionnons la **paire de clés EC2** créé précédemment. <br />\n",
    "Elle nous permettra de se connecter en **ssh** à nos **instances EC2** <br />\n",
    "sans avoir à entrer nos login/mot de passe.<br />\n",
    "On laisse les autres paramètres par défaut. <br />\n",
    "Et enfin, on clique sur \"***Créer un cluster***\"\n",
    " \n",
    "![EMR Sécurité](img/EMR_securite.png)\n",
    "\n",
    "# 7 Instanciation du serveur\n",
    "\n",
    "Il ne nous reste plus qu'à attendre que le serveur soit prêt. <br />\n",
    "Cette étape peut prendre entre **15 et 20 minutes**.\n",
    "\n",
    "<u>Plusieurs étapes s'enchaîne, on peut suivre l'avancé du statut du **cluster EMR**</u> :\n",
    "\n",
    "![Instanciation étape 1](img/EMR_instanciation_01.png)\n",
    "![Instanciation étape 2](img/EMR_instanciation_02.png)\n",
    "![Instanciation étape 3](img/EMR_instanciation_03.png)\n",
    "\n",
    "<u>Lorsque le statut affiche en vert: \"**En attente**\" cela signifie que l'instanciation <br />\n",
    "s'est bien déroulée et que notre serveur est prêt à être utilisé</u>. \n",
    "\n",
    "# 8 Création du tunnel SSH à l'instance EC2 (Maître)\n",
    "\n",
    "## 8.1 Création des autorisations sur les connexions entrantes\n",
    "\n",
    "<u>Nous souhaitons maintenant pouvoir accéder à nos applications</u> :\n",
    " - **JupyterHub** pour l'exécution de notre notebook\n",
    " - **Serveur d'historique Spark** pour le suivi de l'exécution <br />\n",
    "   des tâches de notre script lorsqu'il sera lancé\n",
    " \n",
    "Cependant, <u>ces applications ne sont accessibles que depuis le réseau local du driver</u>, <br />\n",
    "et pour y accéder nous devons **créer un tunnel SSH vers le driver**.\n",
    "\n",
    "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
    "<u>Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
    "il faut modifier le **groupe de sécurité EC2 du driver**</u>.\n",
    "\n",
    "*Il faudra que l'on se connecte en SSH au driver de notre cluster. <br />\n",
    "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
    "Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
    "il faut modifier le groupe de sécurité EC2 du driver. Sur la page de la console <br />\n",
    "consacrée à EC2, dans l'onglet \"Réseau et sécurité\", cliquez sur \"Groupes de sécurité\". <br />\n",
    "Vous allez devoir modifier le groupe de sécurité d’ElasticMapReduce-Master. <br />\n",
    "Dans l'onglet \"Entrant\", ajoutez une règle SSH dont la source est \"N'importe où\" <br />\n",
    "(ou \"Mon IP\" si vous disposez d'une adresse IP fixe).*\n",
    "\n",
    "![Configuration autorisation ports entrants pour ssh](img/EMR_config_ssh_01.png)\n",
    "\n",
    "<u>Une fois cette étape réalisée vous devriez avoir une configuration semblable à la mienne</u> :\n",
    "\n",
    "![Configuration ssh terminée](img/EMR_config_ssh_02.png)\n",
    "\n",
    "## 8.2 Création du tunnel ssh vers le Driver\n",
    "\n",
    "On peut maintenant établir le **tunnel SSH** vers le **Driver**. <br />\n",
    "Pour cela on récupère les informations de connexion fournis par Amazon <br />\n",
    "depuis la page du service EMR / Cluster / onglet Récapitulatif en <br />\n",
    "cliquant sur \"**Activer la connexion Web**\"\n",
    "\n",
    "![Activer la connexion Web](img/EMR_tunnel_ssh_01.png)\n",
    "\n",
    "<u>On récupère ensuite la commande fournis par Amazon pour **établir le tunnel SSH**</u> :\n",
    "\n",
    "![Récupérer la commande pour établir le tunnel ssh](img/EMR_tunnel_ssh_02.png)\n",
    "\n",
    "<u>Dans mon cas, la commande ne fonctionne pas tel</u> quel et j'ai du **l'adapter à ma configuration**. <br />\n",
    "La **clé ssh** se situe dans un dossier \"**.ssh**\" elle-même située dans <br />\n",
    "mon **répertoire personnel** dont le symbole est, sous Linux, identifié par un tilde \"**~**\".\n",
    "\n",
    "<u>Finalement, j'utilise la commande suivante dans un terminal pour établir <br />\n",
    "    mon tunnel ssh (seul l'URL change d'une instance à une autre)</u> : <br />\n",
    "\"**ssh -i ~/.ssh/p8-ec2.pem -D 5555 hadoop@ec2-35-180-91-39.eu-west-3.compute.amazonaws.com**\"\n",
    "\n",
    "<u>On inscrit \"**yes**\" pour valider la connexion et si <br />\n",
    "    la connexion est établit on obtient le résultat suivant</u> :\n",
    "\n",
    "![Création du tunnel SSH](img/EMR_connexion_ssh_01.png)\n",
    "\n",
    "Nous avons **correctement établi le tunnel ssh avec le driver** sur le port \"5555\".\n",
    "\n",
    "## 8.3 Configuration de FoxyProxy\n",
    "\n",
    "Une dernière étape est nécessaire pour accéder à nos applications, <br />\n",
    "en demandant à notre navigateur d'emprunter le tunnel ssh.<br />\n",
    "J'utilise pour cela **FoxyProxy**.\n",
    "\n",
    "Sinon, ouvrez la configuration de **FoxyProxy** et <u>cliquez sur **Ajouter**</u> en haut à gauche <br />\n",
    "puis renseigner les éléments comme dans la capture ci-dessous :\n",
    "\n",
    "![Configuration FoxyProxy Etape 1](img/EMR_foxyproxy_config_01.png)\n",
    "\n",
    "<u>On obtient le résultat ci-dessous</u> :\n",
    "\n",
    "![Configuration FoxyProxy Etape 2](img/EMR_foxyproxy_config_02.png)\n",
    "\n",
    "\n",
    "## 8.4 Accès aux applications du serveur EMR via le tunnel ssh\n",
    "\n",
    "\n",
    "<u>Avant d'établir notre **tunnel ssh** nous avions ça</u> :\n",
    "\n",
    "![avant tunnel ssh](img/EMR_tunnel_ssh_avant.png)\n",
    "\n",
    "<u>On active le **tunnel ssh** comme vu précédemment puis on demande <br />\n",
    "à notre navigateur de l'utiliser avec **FoxyProxy**</u> :\n",
    "\n",
    "![FoxyProxy activation](img/EMR_foxyproxy_activation.png)\n",
    "\n",
    "<u>On peut maintenant s'apercevoir que plusieurs applications nous sont accessibles</u> :\n",
    "\n",
    "![avant tunnel ssh](img/EMR_tunnel_ssh_apres.png)\n",
    "\n",
    "# 9 Connexion au notebook JupyterHub\n",
    "\n",
    "Pour se connecter à **JupyterHub** en vue d'exécuter notre **notebook**, <br />\n",
    "il faut commencer par <u>cliquer sur l'application **JupyterHub**</u> apparu <br />\n",
    "depuis que nous avons configuré le **tunnel ssh** et **foxyproxy** sur <br />\n",
    "notre navigateur (actualisez la page si ce n’est pas le cas).\n",
    "\n",
    "![Démarrage de JupyterHub](img/EMR_jupyterhub_connexion_01.png)\n",
    "\n",
    "On passe les éventuels avertissements de sécurité puis <br />\n",
    "nous arrivons sur une page de connexion.\n",
    "    \n",
    "<u>On se connecte avec les informations par défaut</u> :\n",
    " - <u>login</u>: **jovyan**\n",
    " - <u>password</u>: **jupyter**\n",
    " \n",
    "![Connexion à JupyterHub](img/EMR_jupyterhub_connexion_02.png)\n",
    "\n",
    "Nous arrivons ensuite dans un dossier vierge de notebook.<br />\n",
    "Il suffit d'en créer un en cliquant sur \"**New**\" en haut à droite.\n",
    "\n",
    "![Liste et création des notebook](img/EMR_jupyterhub_creer_notebooks.png)\n",
    "\n",
    "Il est également possible d'en <u>uploader un directement dans notre **bucket S3**</u>.\n",
    "\n",
    "Grace à la <u>**persistance** paramétrée à l'instanciation du cluster <br />\n",
    "nous sommes actuellement dans l'arborescence de notre **bucket S3**</u>\n",
    "\n",
    "![Notebook stockés sur S3](img/EMR_jupyterhub_S3.png)\n",
    "\n",
    "Je décide d'**importer un notebook déjà rédigé en local directement <br />\n",
    "sur S3** et je l'ouvre depuis **l'interface JupyterHub**.\n",
    "\n",
    "# 10 Exécution du code\n",
    "\n",
    "Je décide d'exécuter cette partie du code depuis **JupyterHub hébergé sur notre cluster EMR**.<br />\n",
    "Pour ne pas alourdir inutilement les explications du **notebook**, je ne réexpliquerai pas les étapes communes <br />\n",
    "que nous avons déjà vues dans la première partie où l'on a exécuté le code localement sur notre machine virtuelle Ubuntu.\n",
    "\n",
    "<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n",
    "\n",
    "**En utilisant ce kernel, une session spark est créé à l'exécution de la première cellule**. <br />\n",
    "Il n'est donc **plus nécessaire d'exécuter le code \"spark = (SparkSession ...\"** comme lors <br />\n",
    "de l'exécution de notre notebook en local sur notre VM Ubuntu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e759c1e",
   "metadata": {},
   "source": [
    "## 10.1 Démarrage de la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f0fbe1",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1745362190679_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-18-136.eu-west-3.compute.internal:20888/proxy/application_1745362190679_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-29-196.eu-west-3.compute.internal:8042/node/containerlogs/container_1745362190679_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L'exécution de cette cellule démarre l'application Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba202f",
   "metadata": {},
   "source": [
    "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb788991",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1745362190679_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-18-136.eu-west-3.compute.internal:20888/proxy/application_1745362190679_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-29-196.eu-west-3.compute.internal:8042/node/containerlogs/container_1745362190679_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac9832",
   "metadata": {},
   "source": [
    "## 10.2 Installation des packages\n",
    "\n",
    "Les packages nécessaires ont été installé via l'étape de **bootstrap** à l'instanciation du serveur.\n",
    "\n",
    "## 10.3 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad562eab",
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83663cbd",
   "metadata": {},
   "source": [
    "## 10.4 Définition des PATH pour charger les images et enregistrer les résultats\n",
    "\n",
    "Nous accédons directement à nos **données sur S3** comme si elles étaient **stockées localement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46be859d",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:        s3://p9-data-maodo\n",
      "PATH_Data:   s3://p9-data-maodo/Test\n",
      "PATH_Result: s3://p9-data-maodo/Results"
     ]
    }
   ],
   "source": [
    "PATH = 's3://p9-data-maodo'\n",
    "PATH_Data = PATH+'/Test'\n",
    "PATH_Result = PATH+'/Results'\n",
    "print('PATH:        '+\\\n",
    "      PATH+'\\nPATH_Data:   '+\\\n",
    "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf883c20",
   "metadata": {},
   "source": [
    "## 10.5 Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe93f5",
   "metadata": {},
   "source": [
    "### 10.5.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4b319a",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(PATH_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bfeb4d",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|s3://p9-data-maod...|2025-04-14 12:44:25|  7353|[FF D8 FF E0 00 1...|\n",
      "|s3://p9-data-maod...|2025-04-14 12:44:25|  7350|[FF D8 FF E0 00 1...|\n",
      "|s3://p9-data-maod...|2025-04-14 12:44:25|  7349|[FF D8 FF E0 00 1...|\n",
      "|s3://p9-data-maod...|2025-04-14 12:44:25|  7348|[FF D8 FF E0 00 1...|\n",
      "|s3://p9-data-maod...|2025-04-14 12:44:25|  7328|[FF D8 FF E0 00 1...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "images.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32ac34",
   "metadata": {},
   "source": [
    "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
    "    une colonne contenant les **labels** de chaque image</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52ab808",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "None\n",
      "+------------------------------------------------+----------+\n",
      "|path                                            |label     |\n",
      "+------------------------------------------------+----------+\n",
      "|s3://p9-data-maodo/Test/Watermelon/r_106_100.jpg|Watermelon|\n",
      "|s3://p9-data-maodo/Test/Watermelon/r_109_100.jpg|Watermelon|\n",
      "|s3://p9-data-maodo/Test/Watermelon/r_108_100.jpg|Watermelon|\n",
      "|s3://p9-data-maodo/Test/Watermelon/r_107_100.jpg|Watermelon|\n",
      "|s3://p9-data-maodo/Test/Watermelon/r_95_100.jpg |Watermelon|\n",
      "+------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None"
     ]
    }
   ],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15b199",
   "metadata": {},
   "source": [
    "### 10.5.2 Préparation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7c7165",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                    include_top=True,\n",
    "                    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9bc650",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0d497f2",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc0bf14",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer         │ (None, 224, 224,  │          0 │ -                 │\n",
      "│ (InputLayer)        │ 3)                │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ Conv1 (Conv2D)      │ (None, 112, 112,  │        864 │ input_layer[0][0] │\n",
      "│                     │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ bn_Conv1            │ (None, 112, 112,  │        128 │ Conv1[0][0]       │\n",
      "│ (BatchNormalizatio… │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ Conv1_relu (ReLU)   │ (None, 112, 112,  │          0 │ bn_Conv1[0][0]    │\n",
      "│                     │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expanded_conv_dept… │ (None, 112, 112,  │        288 │ Conv1_relu[0][0]  │\n",
      "│ (DepthwiseConv2D)   │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expanded_conv_dept… │ (None, 112, 112,  │        128 │ expanded_conv_de… │\n",
      "│ (BatchNormalizatio… │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expanded_conv_dept… │ (None, 112, 112,  │          0 │ expanded_conv_de… │\n",
      "│ (ReLU)              │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expanded_conv_proj… │ (None, 112, 112,  │        512 │ expanded_conv_de… │\n",
      "│ (Conv2D)            │ 16)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expanded_conv_proj… │ (None, 112, 112,  │         64 │ expanded_conv_pr… │\n",
      "│ (BatchNormalizatio… │ 16)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_expand      │ (None, 112, 112,  │      1,536 │ expanded_conv_pr… │\n",
      "│ (Conv2D)            │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_expand_BN   │ (None, 112, 112,  │        384 │ block_1_expand[0… │\n",
      "│ (BatchNormalizatio… │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_expand_relu │ (None, 112, 112,  │          0 │ block_1_expand_B… │\n",
      "│ (ReLU)              │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_pad         │ (None, 113, 113,  │          0 │ block_1_expand_r… │\n",
      "│ (ZeroPadding2D)     │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_depthwise   │ (None, 56, 56,    │        864 │ block_1_pad[0][0] │\n",
      "│ (DepthwiseConv2D)   │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_depthwise_… │ (None, 56, 56,    │        384 │ block_1_depthwis… │\n",
      "│ (BatchNormalizatio… │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_depthwise_… │ (None, 56, 56,    │          0 │ block_1_depthwis… │\n",
      "│ (ReLU)              │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_project     │ (None, 56, 56,    │      2,304 │ block_1_depthwis… │\n",
      "│ (Conv2D)            │ 24)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_1_project_BN  │ (None, 56, 56,    │         96 │ block_1_project[… │\n",
      "│ (BatchNormalizatio… │ 24)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_expand      │ (None, 56, 56,    │      3,456 │ block_1_project_… │\n",
      "│ (Conv2D)            │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_expand_BN   │ (None, 56, 56,    │        576 │ block_2_expand[0… │\n",
      "│ (BatchNormalizatio… │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_expand_relu │ (None, 56, 56,    │          0 │ block_2_expand_B… │\n",
      "│ (ReLU)              │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_depthwise   │ (None, 56, 56,    │      1,296 │ block_2_expand_r… │\n",
      "│ (DepthwiseConv2D)   │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_depthwise_… │ (None, 56, 56,    │        576 │ block_2_depthwis… │\n",
      "│ (BatchNormalizatio… │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_depthwise_… │ (None, 56, 56,    │          0 │ block_2_depthwis… │\n",
      "│ (ReLU)              │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_project     │ (None, 56, 56,    │      3,456 │ block_2_depthwis… │\n",
      "│ (Conv2D)            │ 24)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_project_BN  │ (None, 56, 56,    │         96 │ block_2_project[… │\n",
      "│ (BatchNormalizatio… │ 24)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_2_add (Add)   │ (None, 56, 56,    │          0 │ block_1_project_… │\n",
      "│                     │ 24)               │            │ block_2_project_… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_expand      │ (None, 56, 56,    │      3,456 │ block_2_add[0][0] │\n",
      "│ (Conv2D)            │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_expand_BN   │ (None, 56, 56,    │        576 │ block_3_expand[0… │\n",
      "│ (BatchNormalizatio… │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_expand_relu │ (None, 56, 56,    │          0 │ block_3_expand_B… │\n",
      "│ (ReLU)              │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_pad         │ (None, 57, 57,    │          0 │ block_3_expand_r… │\n",
      "│ (ZeroPadding2D)     │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_depthwise   │ (None, 28, 28,    │      1,296 │ block_3_pad[0][0] │\n",
      "│ (DepthwiseConv2D)   │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_depthwise_… │ (None, 28, 28,    │        576 │ block_3_depthwis… │\n",
      "│ (BatchNormalizatio… │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_depthwise_… │ (None, 28, 28,    │          0 │ block_3_depthwis… │\n",
      "│ (ReLU)              │ 144)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_project     │ (None, 28, 28,    │      4,608 │ block_3_depthwis… │\n",
      "│ (Conv2D)            │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_3_project_BN  │ (None, 28, 28,    │        128 │ block_3_project[… │\n",
      "│ (BatchNormalizatio… │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_expand      │ (None, 28, 28,    │      6,144 │ block_3_project_… │\n",
      "│ (Conv2D)            │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_expand_BN   │ (None, 28, 28,    │        768 │ block_4_expand[0… │\n",
      "│ (BatchNormalizatio… │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_expand_relu │ (None, 28, 28,    │          0 │ block_4_expand_B… │\n",
      "│ (ReLU)              │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_depthwise   │ (None, 28, 28,    │      1,728 │ block_4_expand_r… │\n",
      "│ (DepthwiseConv2D)   │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_depthwise_… │ (None, 28, 28,    │        768 │ block_4_depthwis… │\n",
      "│ (BatchNormalizatio… │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_depthwise_… │ (None, 28, 28,    │          0 │ block_4_depthwis… │\n",
      "│ (ReLU)              │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_project     │ (None, 28, 28,    │      6,144 │ block_4_depthwis… │\n",
      "│ (Conv2D)            │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_project_BN  │ (None, 28, 28,    │        128 │ block_4_project[… │\n",
      "│ (BatchNormalizatio… │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_4_add (Add)   │ (None, 28, 28,    │          0 │ block_3_project_… │\n",
      "│                     │ 32)               │            │ block_4_project_… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_expand      │ (None, 28, 28,    │      6,144 │ block_4_add[0][0] │\n",
      "│ (Conv2D)            │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_expand_BN   │ (None, 28, 28,    │        768 │ block_5_expand[0… │\n",
      "│ (BatchNormalizatio… │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_expand_relu │ (None, 28, 28,    │          0 │ block_5_expand_B… │\n",
      "│ (ReLU)              │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_depthwise   │ (None, 28, 28,    │      1,728 │ block_5_expand_r… │\n",
      "│ (DepthwiseConv2D)   │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_depthwise_… │ (None, 28, 28,    │        768 │ block_5_depthwis… │\n",
      "│ (BatchNormalizatio… │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_depthwise_… │ (None, 28, 28,    │          0 │ block_5_depthwis… │\n",
      "│ (ReLU)              │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_project     │ (None, 28, 28,    │      6,144 │ block_5_depthwis… │\n",
      "│ (Conv2D)            │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_project_BN  │ (None, 28, 28,    │        128 │ block_5_project[… │\n",
      "│ (BatchNormalizatio… │ 32)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_5_add (Add)   │ (None, 28, 28,    │          0 │ block_4_add[0][0… │\n",
      "│                     │ 32)               │            │ block_5_project_… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_expand      │ (None, 28, 28,    │      6,144 │ block_5_add[0][0] │\n",
      "│ (Conv2D)            │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_expand_BN   │ (None, 28, 28,    │        768 │ block_6_expand[0… │\n",
      "│ (BatchNormalizatio… │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_expand_relu │ (None, 28, 28,    │          0 │ block_6_expand_B… │\n",
      "│ (ReLU)              │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_pad         │ (None, 29, 29,    │          0 │ block_6_expand_r… │\n",
      "│ (ZeroPadding2D)     │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_depthwise   │ (None, 14, 14,    │      1,728 │ block_6_pad[0][0] │\n",
      "│ (DepthwiseConv2D)   │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_depthwise_… │ (None, 14, 14,    │        768 │ block_6_depthwis… │\n",
      "│ (BatchNormalizatio… │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_depthwise_… │ (None, 14, 14,    │          0 │ block_6_depthwis… │\n",
      "│ (ReLU)              │ 192)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_project     │ (None, 14, 14,    │     12,288 │ block_6_depthwis… │\n",
      "│ (Conv2D)            │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_6_project_BN  │ (None, 14, 14,    │        256 │ block_6_project[… │\n",
      "│ (BatchNormalizatio… │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_expand      │ (None, 14, 14,    │     24,576 │ block_6_project_… │\n",
      "│ (Conv2D)            │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_expand_BN   │ (None, 14, 14,    │      1,536 │ block_7_expand[0… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_expand_relu │ (None, 14, 14,    │          0 │ block_7_expand_B… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_depthwise   │ (None, 14, 14,    │      3,456 │ block_7_expand_r… │\n",
      "│ (DepthwiseConv2D)   │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_depthwise_… │ (None, 14, 14,    │      1,536 │ block_7_depthwis… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_depthwise_… │ (None, 14, 14,    │          0 │ block_7_depthwis… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_project     │ (None, 14, 14,    │     24,576 │ block_7_depthwis… │\n",
      "│ (Conv2D)            │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_project_BN  │ (None, 14, 14,    │        256 │ block_7_project[… │\n",
      "│ (BatchNormalizatio… │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_7_add (Add)   │ (None, 14, 14,    │          0 │ block_6_project_… │\n",
      "│                     │ 64)               │            │ block_7_project_… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_expand      │ (None, 14, 14,    │     24,576 │ block_7_add[0][0] │\n",
      "│ (Conv2D)            │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_expand_BN   │ (None, 14, 14,    │      1,536 │ block_8_expand[0… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_expand_relu │ (None, 14, 14,    │          0 │ block_8_expand_B… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_depthwise   │ (None, 14, 14,    │      3,456 │ block_8_expand_r… │\n",
      "│ (DepthwiseConv2D)   │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_depthwise_… │ (None, 14, 14,    │      1,536 │ block_8_depthwis… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_depthwise_… │ (None, 14, 14,    │          0 │ block_8_depthwis… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_project     │ (None, 14, 14,    │     24,576 │ block_8_depthwis… │\n",
      "│ (Conv2D)            │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_project_BN  │ (None, 14, 14,    │        256 │ block_8_project[… │\n",
      "│ (BatchNormalizatio… │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_8_add (Add)   │ (None, 14, 14,    │          0 │ block_7_add[0][0… │\n",
      "│                     │ 64)               │            │ block_8_project_… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_expand      │ (None, 14, 14,    │     24,576 │ block_8_add[0][0] │\n",
      "│ (Conv2D)            │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_expand_BN   │ (None, 14, 14,    │      1,536 │ block_9_expand[0… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_expand_relu │ (None, 14, 14,    │          0 │ block_9_expand_B… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_depthwise   │ (None, 14, 14,    │      3,456 │ block_9_expand_r… │\n",
      "│ (DepthwiseConv2D)   │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_depthwise_… │ (None, 14, 14,    │      1,536 │ block_9_depthwis… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_depthwise_… │ (None, 14, 14,    │          0 │ block_9_depthwis… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_project     │ (None, 14, 14,    │     24,576 │ block_9_depthwis… │\n",
      "│ (Conv2D)            │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_project_BN  │ (None, 14, 14,    │        256 │ block_9_project[… │\n",
      "│ (BatchNormalizatio… │ 64)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_9_add (Add)   │ (None, 14, 14,    │          0 │ block_8_add[0][0… │\n",
      "│                     │ 64)               │            │ block_9_project_… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_expand     │ (None, 14, 14,    │     24,576 │ block_9_add[0][0] │\n",
      "│ (Conv2D)            │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_expand_BN  │ (None, 14, 14,    │      1,536 │ block_10_expand[… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_expand_re… │ (None, 14, 14,    │          0 │ block_10_expand_… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_depthwise  │ (None, 14, 14,    │      3,456 │ block_10_expand_… │\n",
      "│ (DepthwiseConv2D)   │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_depthwise… │ (None, 14, 14,    │      1,536 │ block_10_depthwi… │\n",
      "│ (BatchNormalizatio… │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_depthwise… │ (None, 14, 14,    │          0 │ block_10_depthwi… │\n",
      "│ (ReLU)              │ 384)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_project    │ (None, 14, 14,    │     36,864 │ block_10_depthwi… │\n",
      "│ (Conv2D)            │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_10_project_BN │ (None, 14, 14,    │        384 │ block_10_project… │\n",
      "│ (BatchNormalizatio… │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_expand     │ (None, 14, 14,    │     55,296 │ block_10_project… │\n",
      "│ (Conv2D)            │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_expand_BN  │ (None, 14, 14,    │      2,304 │ block_11_expand[… │\n",
      "│ (BatchNormalizatio… │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_expand_re… │ (None, 14, 14,    │          0 │ block_11_expand_… │\n",
      "│ (ReLU)              │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_depthwise  │ (None, 14, 14,    │      5,184 │ block_11_expand_… │\n",
      "│ (DepthwiseConv2D)   │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_depthwise… │ (None, 14, 14,    │      2,304 │ block_11_depthwi… │\n",
      "│ (BatchNormalizatio… │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_depthwise… │ (None, 14, 14,    │          0 │ block_11_depthwi… │\n",
      "│ (ReLU)              │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_project    │ (None, 14, 14,    │     55,296 │ block_11_depthwi… │\n",
      "│ (Conv2D)            │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_project_BN │ (None, 14, 14,    │        384 │ block_11_project… │\n",
      "│ (BatchNormalizatio… │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_11_add (Add)  │ (None, 14, 14,    │          0 │ block_10_project… │\n",
      "│                     │ 96)               │            │ block_11_project… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_expand     │ (None, 14, 14,    │     55,296 │ block_11_add[0][… │\n",
      "│ (Conv2D)            │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_expand_BN  │ (None, 14, 14,    │      2,304 │ block_12_expand[… │\n",
      "│ (BatchNormalizatio… │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_expand_re… │ (None, 14, 14,    │          0 │ block_12_expand_… │\n",
      "│ (ReLU)              │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_depthwise  │ (None, 14, 14,    │      5,184 │ block_12_expand_… │\n",
      "│ (DepthwiseConv2D)   │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_depthwise… │ (None, 14, 14,    │      2,304 │ block_12_depthwi… │\n",
      "│ (BatchNormalizatio… │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_depthwise… │ (None, 14, 14,    │          0 │ block_12_depthwi… │\n",
      "│ (ReLU)              │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_project    │ (None, 14, 14,    │     55,296 │ block_12_depthwi… │\n",
      "│ (Conv2D)            │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_project_BN │ (None, 14, 14,    │        384 │ block_12_project… │\n",
      "│ (BatchNormalizatio… │ 96)               │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_12_add (Add)  │ (None, 14, 14,    │          0 │ block_11_add[0][… │\n",
      "│                     │ 96)               │            │ block_12_project… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_expand     │ (None, 14, 14,    │     55,296 │ block_12_add[0][… │\n",
      "│ (Conv2D)            │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_expand_BN  │ (None, 14, 14,    │      2,304 │ block_13_expand[… │\n",
      "│ (BatchNormalizatio… │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_expand_re… │ (None, 14, 14,    │          0 │ block_13_expand_… │\n",
      "│ (ReLU)              │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_pad        │ (None, 15, 15,    │          0 │ block_13_expand_… │\n",
      "│ (ZeroPadding2D)     │ 576)              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_depthwise  │ (None, 7, 7, 576) │      5,184 │ block_13_pad[0][… │\n",
      "│ (DepthwiseConv2D)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_depthwise… │ (None, 7, 7, 576) │      2,304 │ block_13_depthwi… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_depthwise… │ (None, 7, 7, 576) │          0 │ block_13_depthwi… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_project    │ (None, 7, 7, 160) │     92,160 │ block_13_depthwi… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_13_project_BN │ (None, 7, 7, 160) │        640 │ block_13_project… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_expand     │ (None, 7, 7, 960) │    153,600 │ block_13_project… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_expand_BN  │ (None, 7, 7, 960) │      3,840 │ block_14_expand[… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_expand_re… │ (None, 7, 7, 960) │          0 │ block_14_expand_… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_depthwise  │ (None, 7, 7, 960) │      8,640 │ block_14_expand_… │\n",
      "│ (DepthwiseConv2D)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_depthwise… │ (None, 7, 7, 960) │      3,840 │ block_14_depthwi… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_depthwise… │ (None, 7, 7, 960) │          0 │ block_14_depthwi… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_project    │ (None, 7, 7, 160) │    153,600 │ block_14_depthwi… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_project_BN │ (None, 7, 7, 160) │        640 │ block_14_project… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_14_add (Add)  │ (None, 7, 7, 160) │          0 │ block_13_project… │\n",
      "│                     │                   │            │ block_14_project… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_expand     │ (None, 7, 7, 960) │    153,600 │ block_14_add[0][… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_expand_BN  │ (None, 7, 7, 960) │      3,840 │ block_15_expand[… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_expand_re… │ (None, 7, 7, 960) │          0 │ block_15_expand_… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_depthwise  │ (None, 7, 7, 960) │      8,640 │ block_15_expand_… │\n",
      "│ (DepthwiseConv2D)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_depthwise… │ (None, 7, 7, 960) │      3,840 │ block_15_depthwi… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_depthwise… │ (None, 7, 7, 960) │          0 │ block_15_depthwi… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_project    │ (None, 7, 7, 160) │    153,600 │ block_15_depthwi… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_project_BN │ (None, 7, 7, 160) │        640 │ block_15_project… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_15_add (Add)  │ (None, 7, 7, 160) │          0 │ block_14_add[0][… │\n",
      "│                     │                   │            │ block_15_project… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_expand     │ (None, 7, 7, 960) │    153,600 │ block_15_add[0][… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_expand_BN  │ (None, 7, 7, 960) │      3,840 │ block_16_expand[… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_expand_re… │ (None, 7, 7, 960) │          0 │ block_16_expand_… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_depthwise  │ (None, 7, 7, 960) │      8,640 │ block_16_expand_… │\n",
      "│ (DepthwiseConv2D)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_depthwise… │ (None, 7, 7, 960) │      3,840 │ block_16_depthwi… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_depthwise… │ (None, 7, 7, 960) │          0 │ block_16_depthwi… │\n",
      "│ (ReLU)              │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_project    │ (None, 7, 7, 320) │    307,200 │ block_16_depthwi… │\n",
      "│ (Conv2D)            │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ block_16_project_BN │ (None, 7, 7, 320) │      1,280 │ block_16_project… │\n",
      "│ (BatchNormalizatio… │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ Conv_1 (Conv2D)     │ (None, 7, 7,      │    409,600 │ block_16_project… │\n",
      "│                     │ 1280)             │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ Conv_1_bn           │ (None, 7, 7,      │      5,120 │ Conv_1[0][0]      │\n",
      "│ (BatchNormalizatio… │ 1280)             │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ out_relu (ReLU)     │ (None, 7, 7,      │          0 │ Conv_1_bn[0][0]   │\n",
      "│                     │ 1280)             │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ global_average_poo… │ (None, 1280)      │          0 │ out_relu[0][0]    │\n",
      "│ (GlobalAveragePool… │                   │            │                   │\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      " Total params: 2,257,984 (8.61 MB)\n",
      " Trainable params: 2,223,872 (8.48 MB)\n",
      " Non-trainable params: 34,112 (133.25 KB)"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8fe2b9",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f135",
   "metadata": {},
   "source": [
    "### 10.5.3 Définition du processus de chargement des images <br/> et application de leur featurisation à travers l'utilisation de pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "933100cf",
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt1/yarn/usercache/livy/appcache/application_1745253785218_0005/container_1745253785218_0005_01_000001/pyspark.zip/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details."
     ]
    }
   ],
   "source": [
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23206e8",
   "metadata": {},
   "source": [
    "### 10.5.4 Exécutions des actions d'extractions de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22d760c2",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e07fd68",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_df = images.repartition(24).select(col(\"path\"),\n",
    "                                            col(\"label\"),\n",
    "                                            featurize_udf(\"content\").alias(\"features\")\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a930b3",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://p9-data-maodo/Results"
     ]
    }
   ],
   "source": [
    "print(PATH_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c53ddd5",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b3237",
   "metadata": {},
   "source": [
    "### Reduction de la dimension sur le cloud (méthode PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c47a029",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors,VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee29e8",
   "metadata": {},
   "source": [
    "**Conversion des images en vecteur dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1f156b",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conversion des données images en vecteur dense via une fonction UDF \n",
    "array_to_dense_vector_udf = udf(lambda arr: Vectors.dense(arr), VectorUDT())\n",
    "# Appliquer la fonction UDF pour créer la nouvelle colonne \"dense_features_vector\"\n",
    "features_df = features_df.withColumn(\"dense_features\", array_to_dense_vector_udf(features_df[\"features\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd07047",
   "metadata": {},
   "source": [
    "**Analyse en composantes principales(PCA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a0f41f7",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion de variance expliquee par les 300 premi?res composantes : 94.06%"
     ]
    }
   ],
   "source": [
    "# Analyse en composantes principales (ACP) avec 300 composantes principales \n",
    "pca = PCA(k=300, inputCol=\"dense_features\", outputCol=\"pca_features\")\n",
    "\n",
    "# Ajustement du modèle PCA \n",
    "pca_model = pca.fit(features_df)\n",
    "\n",
    "# Calcul de la variance expliquée\n",
    "explained_variance = pca_model.explainedVariance \n",
    "\n",
    "# Calcul de la variance expliquée cumulée\n",
    "explained_variance_sum = explained_variance.sum()\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Proportion de variance expliquee par les 300 premières composantes : {explained_variance_sum * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18af929e",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|                path|         label|        pca_features|\n",
      "+--------------------+--------------+--------------------+\n",
      "|s3://p9-data-maod...|Pineapple Mini|[-4.3388236618355...|\n",
      "|s3://p9-data-maod...|Pineapple Mini|[-3.9431978618737...|\n",
      "|s3://p9-data-maod...|Pineapple Mini|[-6.5375318264422...|\n",
      "|s3://p9-data-maod...|   Cauliflower|[-4.3619869651341...|\n",
      "|s3://p9-data-maod...|Pineapple Mini|[-6.6830714556236...|\n",
      "+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Transformation des images sur les 300 premières composantes\n",
    "df_pca_transformed = pca_model.transform(features_df)\n",
    "\n",
    "# Sélectionner les colonnes pertinentes et afficher les premières lignes\n",
    "df_pca = df_pca_transformed.select(\"path\", \"label\", \"pca_features\")\n",
    "\n",
    "df_pca.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e27179",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:        s3://p9-data-maodo\n",
      "PATH_Result_ACP: s3://p9-data-maodo/Result_ACP"
     ]
    }
   ],
   "source": [
    "PATH_Result_ACP = PATH+'/Result_ACP'\n",
    "\n",
    "print('PATH:        '+\\\n",
    "      PATH+\n",
    "      '\\nPATH_Result_ACP: '+PATH_Result_ACP\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99e9cc06",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Écrire le résultat dans un fichier parquet\n",
    "df_pca.write.mode(\"overwrite\").parquet(PATH_Result_ACP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe01b72",
   "metadata": {},
   "source": [
    "## 10.6 Chargement des données enregistrées et validation du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db18a784",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d750d2a8",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path  ...                                           features\n",
      "0   s3://p9-data-maodo/Test/Watermelon/r_108_100.jpg  ...  [0.0, 0.4033173, 0.021847043, 0.0, 1.5623505, ...\n",
      "1    s3://p9-data-maodo/Test/Watermelon/r_89_100.jpg  ...  [0.18327457, 0.06301979, 0.0, 0.06413626, 0.78...\n",
      "2    s3://p9-data-maodo/Test/Watermelon/r_69_100.jpg  ...  [1.1646465, 0.31732556, 0.0, 0.0, 0.6920591, 0...\n",
      "3  s3://p9-data-maodo/Test/Pineapple Mini/122_100...  ...  [0.0, 4.3337703, 0.0068556434, 0.0, 0.0, 0.0, ...\n",
      "4  s3://p9-data-maodo/Test/Pineapple Mini/268_100...  ...  [0.0, 5.1022515, 0.0, 0.0, 0.0, 0.0, 0.1004548...\n",
      "\n",
      "[5 rows x 3 columns]"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b29205ff",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280,)"
     ]
    }
   ],
   "source": [
    "df.loc[0,'features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fba6455",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22688, 3)"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72974aab",
   "metadata": {},
   "source": [
    "<u>On peut également constater la présence des fichiers <br />\n",
    "    au format \"**parquet**\" sur le **serveur S3**</u> :\n",
    "\n",
    "![Affichage des résultats sur S3](img/S3_Results.png)\n",
    "\n",
    "# 11 Suivi de l'avancement des tâches avec le Serveur d'Historique Spark\n",
    "\n",
    "Il est possible de voir l'avancement des tâches en cours <br />\n",
    "avec le **serveur d'historique Spark**.\n",
    "\n",
    "![Accès au serveur d'historique spark](img/EMR_serveur_historique_spark_acces.png)\n",
    "\n",
    "**Il est également possible de revenir et d'étudier les tâches <br />\n",
    "qui ont été réalisé, afin de debugger, optimiser les futurs <br />\n",
    "tâches à réaliser.**\n",
    "\n",
    "<u>Lorsque la commande \"**features_df.write.mode(\"overwrite\").parquet(PATH_Result)**\" <br />\n",
    "était en cours, nous pouvions observer son état d'avancement</u> :\n",
    "\n",
    "![Progression execution script](img/EMR_jupyterhub_avancement.png)\n",
    "\n",
    "<u>Le **serveur d'historique Spark** nous permet une vision beaucoup plus précise <br />\n",
    "de l'exécution des différentes tâche sur les différentes machines du cluster</u> :\n",
    "\n",
    "![Suivi des tâches spark](img/EMR_SHSpark_01.png)\n",
    "\n",
    "On peut également constater que notre cluster de calcul a mis <br />\n",
    "un tout petit peu **moins de 8 minutes** pour traiter les **22 688 images**.\n",
    "\n",
    "![Temps de traitement](img/EMR_SHSpark_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d65bf",
   "metadata": {},
   "source": [
    "# 12 Résiliation de l'instance EMR\n",
    "\n",
    "Notre travail est maintenant terminé. <br />\n",
    "Le cluster de machines EMR est **facturé à la demande**, <br />\n",
    "et nous continuons d'être facturé même lorsque <br />\n",
    "les machines sont au repos.<br />\n",
    "Pour **optimiser la facturation**, il nous faut <br />\n",
    "maintenant **résilier le cluster**.\n",
    "\n",
    "<u>Je réalise cette commande depuis l'interface AWS</u> :\n",
    "\n",
    "1. Commencez par **désactiver le tunnel ssh dans FoxyProxy** pour éviter des problèmes de **timeout**.\n",
    "![Désactivation de FoxyProxy](img/EMR_foxyproxy_desactivation.png)\n",
    "2. Cliquez sur \"**Résilier**\"\n",
    "![Cliquez sur Résilier](img/EMR_resiliation_01.png)\n",
    "3. Confirmez la résiliation\n",
    "![Confirmez la résiliation](img/EMR_resiliation_02.png)\n",
    "4. La résiliation prend environ **1 minute**\n",
    "![Résiliation en cours](img/EMR_resiliation_03.png)\n",
    "5. La résiliation est effectuée\n",
    "![Résiliation terminée](img/EMR_resiliation_04.png)\n",
    "\n",
    "# 13 Cloner le serveur EMR (si besoin)\n",
    "\n",
    "Si nous devons de nouveau exécuter notre notebook dans les mêmes conditions, <br />\n",
    "il nous suffit de **cloner notre cluster** et ainsi en obtenir une copie fonctionnelle <br />\n",
    "sous 15/20 minutes, le temps de son instanciation.\n",
    "\n",
    "<u>Pour cela deux solutions</u> :\n",
    "1. <u>Depuis l'interface AWS</u> :\n",
    " 1. Cliquez sur \"**Cloner**\"\n",
    "   ![Cloner un cluster](img/EMR_cloner_01.png)\n",
    " 2. Dans notre cas nous ne souhaitons pas inclure d'étapes\n",
    "   ![Ne pas inclure d'étapes](img/EMR_cloner_02.png)\n",
    " 3. La configuration du cluster est recréée à l’identique. <br />\n",
    "    On peut revenir sur les différentes étapes si on souhaite apporter des modifications<br />\n",
    "    Quand tout est prêt, cliquez sur \"**Créer un cluster**\"\n",
    "  ![Vérification/Modification/Créer un cluster](img/EMR_cloner_03.png)\n",
    "2. <u>En ligne de commande</u> (avec AWS CLI d'installé et de configuré et en s'assurant <br />\n",
    "   de s'attribuer les droits nécessaires sur le compte AMI utilisé)\n",
    " 1. Cliquez sur \"**Exporter AWS CLI**\"\n",
    " ![Exporter AWS CLI](img/EMR_cloner_cli_01.png)\n",
    " 2. Copier/Coller la commande **depuis un terminal**\n",
    " ![Copier Coller Commande](img/EMR_cloner_cli_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba46f9",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Nous avons réalisé ce projet **en deux temps** en tenant <br />\n",
    "compte des contraintes qui nous ont été imposées.\n",
    "\n",
    "Nous avons **dans un premier temps développé notre solution en local** <br />\n",
    "sur une machine virtuelle dans un environnement Linux Ubuntu.\n",
    "\n",
    "La <u>première phase</u> a consisté à **installer l'environnement de travail Spark**. <br />\n",
    "**Spark** a un paramètre qui nous permet de travaillé en local et nous permet <br />\n",
    "ainsi de **simuler du calcul partagé** en considérant <br />\n",
    "**chaque cœur d'un processeur comme un worker indépendant**.<br />\n",
    "Nous avons travaillé sur un plus **petit jeu de donnée**, l'idée était <br />\n",
    "simplement de **valider le bon fonctionnement de la solution**.\n",
    "\n",
    "Nous avons fait le choix de réaliser du **transfert learning** <br />\n",
    "à partir du model **MobileNetV2**.<br />\n",
    "Ce modèle a été retenu pour sa **légèreté** et sa **rapidité d'exécution** <br />\n",
    "ainsi que pour la **faible dimension de son vecteur en sortie**.\n",
    "\n",
    "Les résultats ont été enregistrés sur disque en plusieurs <br />\n",
    "partitions au format \"**parquet**\".\n",
    "\n",
    "<u>**La solution a parfaitement fonctionné en mode local**</u>.\n",
    "\n",
    "La <u>deuxième phase</u> a consisté à créer un **réel cluster de calculs**. <br />\n",
    "L'objectif était de pouvoir **anticiper une future augmentation de la charge de travail**.\n",
    "\n",
    "Le meilleur choix retenu a été l'utilisation du prestataire de services **Amazon Web Services** <br />\n",
    "qui nous permet de **louer à la demande de la puissance de calculs**, <br />\n",
    "pour un **coût tout à fait acceptable**.<br />\n",
    "Ce service se nomme **EC2** et se classe parmi les offres **Infrastructure As A Service** (IAAS).\n",
    "\n",
    "Nous sommes allez plus loin en utilisant un service de plus <br />\n",
    "haut niveau (**Plateforme As A Service** PAAS)<br />\n",
    "en utilisant le service **EMR** qui nous permet d'un seul coup <br />\n",
    "d'**instancier plusieurs serveur (un cluster)** sur lesquels <br />\n",
    "nous avons pu demander l'installation et la configuration de plusieurs<br />\n",
    "programmes et librairies nécessaires à notre projet comme **Spark**, <br />\n",
    "**Hadoop**, **JupyterHub** ainsi que la librairie **TensorFlow**.\n",
    "\n",
    "En plus d'être plus **rapide et efficace à mettre en place**, nous avons <br />\n",
    "la **certitude du bon fonctionnement de la solution**, celle-ci ayant été <br />\n",
    "préalablement validé par les ingénieurs d'Amazon.\n",
    "\n",
    "Nous avons également pu installer, sans difficulté, **les packages <br />\n",
    "nécessaires sur l'ensembles des machines du cluster**.\n",
    "\n",
    "Enfin, avec très peu de modification, et plus simplement encore, <br />\n",
    "nous avons pu **exécuter notre notebook comme nous l'avions fait localement**.<br />\n",
    "Nous avons cette fois-ci exécuté le traitement sur **l'ensemble des images de notre dossier \"Test\"**.\n",
    "\n",
    "Nous avons opté pour le service **Amazon S3** pour **stocker les données de notre projet**. <br />\n",
    "S3 offre, pour un faible coût, toutes les conditions dont nous avons besoin pour stocker <br />\n",
    "et exploiter de manière efficace nos données.<br />\n",
    "L'espace alloué est potentiellement **illimité**, mais les coûts seront fonction de l'espace utilisé.\n",
    "\n",
    "Il nous sera **facile de faire face à une monté de la charge de travail** en **redimensionnant** <br />\n",
    "simplement notre cluster de machines (horizontalement et/ou verticalement au besoin), <br />\n",
    "les coûts augmenteront en conséquence mais resteront nettement inférieurs aux coûts engendrés <br />\n",
    "par l'achat de matériels ou par la location de serveurs dédiés."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
